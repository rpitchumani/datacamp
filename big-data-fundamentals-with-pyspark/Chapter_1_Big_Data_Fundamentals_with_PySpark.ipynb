{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf56e3c1-126e-4608-a684-2937c6c527ac",
   "metadata": {},
   "source": [
    "# Big Data Fundamentals with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffba23-4f5b-46ea-9c3a-6e3759b33a96",
   "metadata": {},
   "source": [
    "## Chapter 1: Introduction to Big Data analysis with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c7b620-52d4-4774-afe5-f632a5967fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0414eb4f-948d-441f-9843-494242f6b790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[1] appName=SparkByExamples.com>\n",
      "Spark App Name : SparkByExamples.com\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession from builder\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "print(spark.sparkContext)\n",
    "print(\"Spark App Name : \"+ spark.sparkContext.appName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4049566-a253-4b3a-b3ca-d9345759038e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4724f27f-161a-4ea6-8d00-699262d581e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of Spark Context in the PySpark shell is 3.5.0\n",
      "The Python version of Spark Context in the PySpark shell is 3.10\n",
      "The master of Spark Context in the PySpark shell is local[1]\n"
     ]
    }
   ],
   "source": [
    "# Print the version of SparkContext\n",
    "print(\"The version of Spark Context in the PySpark shell is\", sc.version)\n",
    "\n",
    "# Print the Python version of SparkContext\n",
    "print(\"The Python version of Spark Context in the PySpark shell is\", sc.pythonVer)\n",
    "\n",
    "# Print the master of SparkContext\n",
    "print(\"The master of Spark Context in the PySpark shell is\", sc.master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca3979e3-a8a5-4ba2-a1a6-dda373588c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[14] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "# Create a Python list of numbers from 1 to 100 \n",
    "numb = range(1, 100)\n",
    "\n",
    "# Load the list into PySpark  \n",
    "spark_data = sc.parallelize(numb)\n",
    "print(spark_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5df9215a-5ab7-49a2-992d-e1575551d732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md MapPartitionsRDD[16] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "# Load a local file into PySpark shell\n",
    "file_path = \"README.md\"\n",
    "lines = sc.textFile(file_path)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82cfdb74-4468-4b89-ab43-bfc22b048675",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input list is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "The squared numbers are [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "my_list = list(range(1, 11))\n",
    "\n",
    "# Print my_list in the console\n",
    "print(\"Input list is\", my_list)\n",
    "\n",
    "# Square all numbers in my_list\n",
    "squared_list_lambda = list(map(lambda x: x*x, my_list))\n",
    "\n",
    "# Print the result of the map function\n",
    "print(\"The squared numbers are\", squared_list_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6c06e1f-4a85-40c8-acee-11af2eddfc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input list is: [10, 21, 31, 40, 51, 60, 72, 80, 93, 101]\n",
      "Numbers divisible by 10 are: [10, 40, 60, 80]\n"
     ]
    }
   ],
   "source": [
    "my_list2 = [10, 21, 31, 40, 51, 60, 72, 80, 93, 101]\n",
    "\n",
    "# Print my_list2 in the console\n",
    "print(\"Input list is:\", my_list2)\n",
    "\n",
    "# Filter numbers divisible by 10\n",
    "filtered_list = list(filter(lambda x: (x%10 == 0), my_list2))\n",
    "\n",
    "# Print the numbers divisible by 10\n",
    "print(\"Numbers divisible by 10 are:\", filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008635d3-dd48-4110-a67f-cbd334a55b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
